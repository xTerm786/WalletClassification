{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36c9ae6-5f17-4564-a6a8-715b0a595d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Set your OpenAI API key\u001b[39;00m\n\u001b[1;32m     14\u001b[0m dotenv_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize OpenAI client with API key\u001b[39;00m\n\u001b[1;32m     18\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "config = dotenv_values(\".env\")\n",
    "api_key = config[\"API_KEY\"]\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# Function to embed a batch of texts using OpenAI's embedding model\n",
    "def embed_text_batch(texts):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,  # The texts to be embedded\n",
    "        model=\"text-embedding-3-small\"  # The model used for embedding\n",
    "    )\n",
    "    return [item.embedding for item in response.data]  # Return the embeddings\n",
    "\n",
    "# Load the new CSV file\n",
    "file_path = 'bigNewWalletData.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Randomize the order of the rows in the dataframe and select 50 random rows \n",
    "# <!--- Thomas: There is only 200 rows in the csv being passed in\n",
    "df = df.sample(n=50, random_state=42).reset_index(drop=True) # <!--- Jonathan: I changed the value to 1000 to 50\n",
    "\n",
    "\n",
    "# Prepare the text data and labels\n",
    "X = df['Address'].tolist()\n",
    "y = df['Label']\n",
    "\n",
    "# Embed the text data\n",
    "embeddings = embed_text_batch(X)\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "X_embeddings = np.array(embeddings)\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of the embeddings to 10 components\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_embeddings)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Private\", \"Public\"], yticklabels=[\"Private\", \"Public\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Create a DataFrame for the test set with original columns\n",
    "df_test = df.loc[y_test.index].copy()\n",
    "df_test['ADDRESS'] = [list(X_pca[i]) for i in range(len(y_test))]\n",
    "df_test['Predicted Label'] = y_pred\n",
    "\n",
    "# Save the test results to a CSV\n",
    "results_csv_path = 'nw_test_results.csv' # <!--- Thomas: The file name saved has to be a different name \n",
    "# then the file being passed in\n",
    "df_test.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f\"Test results saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5e53a-37a8-4c0d-a8a3-4fe021198d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming you have a trained model named 'model'\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'WalletClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7cc1ba-a2e1-41ae-9807-c9a429ffcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check, run to load model again\n",
    "\n",
    "# To load the model from the file\n",
    "loaded_model = joblib.load('WalletClassifier.pkl')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "290967ab-8dfe-422a-b560-1bab8053e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37167275, 0.62832725],\n",
       "       [0.34881526, 0.65118474],\n",
       "       [0.38626617, 0.61373383],\n",
       "       [0.62088547, 0.37911453],\n",
       "       [0.60721039, 0.39278961],\n",
       "       [0.63717296, 0.36282704],\n",
       "       [0.38113952, 0.61886048],\n",
       "       [0.36936055, 0.63063945],\n",
       "       [0.35730239, 0.64269761],\n",
       "       [0.396649  , 0.603351  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eca90c-3847-494c-99ed-2b5ad3cda382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
